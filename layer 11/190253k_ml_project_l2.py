# -*- coding: utf-8 -*-
"""190253K_ml_project-l2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VkMVfPT5-jrtOUim9cr3Uie582g20tQV
"""

# import libraries
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.model_selection import RandomizedSearchCV
from sklearn.decomposition import PCA
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

# read the test and train data files
train_df = pd.read_csv("train.csv")
valid_df = pd.read_csv("valid.csv")
test_df = pd.read_csv("test.csv")

"""Label 2"""

train_2_df = train_df.iloc[:, :-2]
valid_2_df = valid_df.iloc[:, :-2]
test_2_df = test_df.iloc[:, 1:]

train_2_df.drop(columns=["label_1"], inplace=True)
valid_2_df.drop(columns=["label_1"], inplace=True)

train_2_df.isna().sum()

valid_2_df.isna().sum()

# splitting the test and train datasets into X and Y values
X_2_train= train_2_df.iloc[:,0:-1].values
Y_2_train = train_2_df.iloc[:,-1].values
X_2_valid = valid_2_df.iloc[:,0:-1].values
Y_2_valid = valid_2_df.iloc[:,-1].values
X_2_test = test_2_df.iloc[:, :].values

imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
Y_2_train = imputer.fit_transform(Y_2_train.reshape(-1, 1)).flatten().astype(int)

imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
Y_2_valid = imputer.fit_transform(Y_2_valid.reshape(-1, 1)).flatten().astype(int)

# scalling and fitting data
scaler = StandardScaler()
scaler.fit(X_2_train)

X_2_train = scaler.transform(X_2_train)
X_2_valid = scaler.transform(X_2_valid)
X_2_test = scaler.transform(X_2_test)

# compare models using cross validation
models = [RandomForestClassifier(), SVC(kernel='linear'), KNeighborsClassifier(n_neighbors=5)]

for model in models:
    cv_score = cross_val_score(model, X_2_train, Y_2_train, cv=5)
    mean_accuracy = round((sum(cv_score)/len(cv_score))*100,2)
    print("Mean accuracy % of the model: ", model, mean_accuracy)

# Use SVC since it has the highest accuracy
model = SVC()
model.fit(X_2_train, Y_2_train)

y_2_valid_pred = model.predict(X_2_valid)
y_2_test_pred = model.predict(X_2_test)
print(classification_report(Y_2_valid, y_2_valid_pred))

# Create a SelectKBest instance with f_classif scoring function and select top 2 features
k = 250
selector = SelectKBest(score_func=f_classif, k=k)

# Fit and transform the data
X_2_best_train = selector.fit_transform(X_2_train, Y_2_train)
X_2_best_valid = selector.transform(X_2_valid)
X_2_best_test = selector.transform(X_2_test)

X_2_best_train.shape

model.fit(X_2_best_train, Y_2_train)
y_2_pred_after = model.predict(X_2_best_valid)
print(classification_report(Y_2_valid, y_2_pred_after))

pca=PCA(0.99)
pca = pca.fit(X_2_train)

x_2_train_pca=pca.fit_transform(X_2_best_train)
x_2_valid_pca = pca.transform(X_2_best_valid)
x_2_test_pca = pca.transform(X_2_best_test)

# Use KNeighborsClassifier
model.fit(x_2_train_pca, Y_2_train)

y_2_pred_after = model.predict(x_2_valid_pca)
print(classification_report(Y_2_valid, y_2_pred_after))

x_2_train_pca.shape

param_grid = {
    'C': [0.1, 1, 10],          # Regularization parameter
    'kernel': ['linear', 'rbf'],  # Kernel type
    'gamma': ['scale', 'auto']   # Kernel coefficient for 'rbf' kernel
}

# Create a GridSearchCV object with cross-validation (e.g., 5-fold cross-validation)
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')

# Fit the GridSearchCV instance to the training data
grid_search.fit(x_2_train_pca, Y_2_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

# Evaluate the best model on the test set
y_2_pred_after = best_model.predict(x_2_valid_pca)
preds = best_model.predict(x_2_test_pca)

print("Best Hyperparameters:", best_params)
print(classification_report(Y_2_valid, y_2_pred_after))

data_frame = pd.DataFrame(preds, columns=["label_2"])
data_frame.to_csv(f"190253K_2.csv",na_rep='')

